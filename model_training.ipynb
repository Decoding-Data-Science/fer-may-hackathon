{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17d08e51-cdd4-452b-ab39-e5299e543107",
   "metadata": {},
   "source": [
    "The following is the training sequence of a light weight model used for emotion detection on video frames. The model is small to increase the inference speed while maintaining a decent accuracy. It was further quantised from 8mb to 2 mb post training. Here is the demo video link: https://drive.google.com/file/d/1atuPCgSzteMwL30KOVUDsYgNZSkelzgI/view?usp=drive_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a847c7a-fac0-4530-b49a-c9b414807b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Requirement already satisfied: numpy in c:\\python312\\lib\\site-packages (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow\n",
    "!pip install -q tensorflow-model-optimization\n",
    "!pip install numpy\n",
    "!pip install keras seaborn scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aef1b7-c297-4117-a855-f512f5105d8a",
   "metadata": {},
   "source": [
    "The following section is data preparation. To run this sequence, create a folder named 'images' in the root of the project. It should have 2 folders, 'train' and 'validation'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1786eb7f-6eef-48b2-9195-6be97b127353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def extract_dataset(main_folder, image_size=(48, 48)):\n",
    "    train_dataset = []\n",
    "    train_labels = []\n",
    "    val_dataset = []\n",
    "    val_labels = []\n",
    "\n",
    "    # Define a dictionary to map each emotion to a unique label\n",
    "    emotion_labels = {'neutral': 0, 'happy': 1,'angry': 2 , 'surprise':3,'sad':4}\n",
    "\n",
    "    # Loop through emotions in the main folder\n",
    "    for emotion in emotion_labels:\n",
    "        train_folder = os.path.join(main_folder, 'train', emotion)\n",
    "        val_folder = os.path.join(main_folder, 'validation', emotion)\n",
    "        label = emotion_labels[emotion]\n",
    "\n",
    "        # Training set\n",
    "        for filename in os.listdir(train_folder):\n",
    "            if filename.endswith(('.jpg', '.jpeg', '.png', '.JPG')):  \n",
    "                image_path = os.path.join(train_folder, filename)\n",
    "\n",
    "                # Loading the image using TensorFlow and convert to grayscale\n",
    "                img = load_img(image_path, color_mode='grayscale', target_size=image_size)\n",
    "                img_array = img_to_array(img)\n",
    "\n",
    "                # Normalize the pixel values to the range [0, 1]\n",
    "                img_array /= 255.0\n",
    "\n",
    "                # Append the image data and label to the training dataset\n",
    "                train_dataset.append(img_array)\n",
    "                train_labels.append(label)\n",
    "\n",
    "        # Validation set\n",
    "        for filename in os.listdir(val_folder):\n",
    "            if filename.endswith(('.jpg', '.jpeg', '.png', '.JPG')):  \n",
    "                image_path = os.path.join(val_folder, filename)\n",
    "\n",
    "                # Loading the image using TensorFlow and converting to grayscale\n",
    "                img = load_img(image_path, color_mode='grayscale', target_size=image_size)\n",
    "                img_array = img_to_array(img)\n",
    "\n",
    "                # Normalize the pixel values to the range [0, 1]\n",
    "                img_array /= 255.0\n",
    "\n",
    "                # Append the image data to the validation dataset\n",
    "                val_dataset.append(img_array)\n",
    "                val_labels.append(label)\n",
    "\n",
    "    return train_dataset, train_labels, val_dataset, val_labels\n",
    "    \n",
    "main_folder_path = '/images'  \n",
    "image_size = (48, 48)\n",
    "\n",
    "train_dataset, train_labels, val_dataset, val_labels = extract_dataset(main_folder_path, image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0dd97e-4d17-4f77-89de-d7501cb8a4e0",
   "metadata": {},
   "source": [
    "The following code defines the model. We are using vggnet16 architecture with the fer2013 dataset. The inputs are grey scale 48 x 48 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ea1673-3e38-45da-80ac-b86463f5f7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout,BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "from sklearn.utils import class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import tf_keras as keras\n",
    "import tempfile\n",
    "\n",
    "def create_vggnet16_model(input_shape=(48, 48, 1)):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d2c686-1aa3-47ad-a9c4-7a0ab6376e3a",
   "metadata": {},
   "source": [
    "These are some graph plotting functions. They have been taken as a sample from the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203cf059-cb5e-49ae-bc93-a36411ebb432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Get unique classes from the data\n",
    "    unique_classes = np.unique(np.concatenate([y_true, y_pred]))\n",
    "\n",
    "    # Display confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "    disp.plot(cmap='Blues', values_format='d')\n",
    "\n",
    "    # Update tick locations based on unique classes\n",
    "    plt.xticks(np.arange(len(unique_classes)), unique_classes, rotation=45)\n",
    "    plt.yticks(np.arange(len(unique_classes)), unique_classes)\n",
    "    \n",
    "    plt.show()\n",
    "def plot_accuracy_curves(history):\n",
    "    # Plot train accuracy and validation accuracy over epochs\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Training Vs Validation Accuracy')\n",
    "    plt.show()    \n",
    "\n",
    "def plot_loss_curves(history):\n",
    "    # Plot train loss and validation loss over epochs\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training Vs Validation Loss')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07966a86-e87a-4300-8828-2ab7529b1abf",
   "metadata": {},
   "source": [
    "This is the main training sequence. We have used Adams optimizer and sparse categorical crossentropy as our loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fabee30-2034-49ba-a2c3-f959132147e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vgg(dataset, labels, learning_rate=0.001, batch_size=32, test_size=0.2, epochs=10, patience=3):\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=test_size, random_state=42)\n",
    "\n",
    "    # Compute class weights\n",
    "    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "    print(class_weight_dict)\n",
    "    \n",
    "    # Create and compile the VGGNet16 model\n",
    "    model = create_vggnet16_model()\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Define early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "\n",
    "    # Train the model with class weights\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test),\n",
    "                        callbacks=[early_stopping], class_weight=class_weight_dict)\n",
    "\n",
    "    # Quantize the model\n",
    "    \n",
    "\n",
    "    # Evaluate the quantized model\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Optionally, you can also evaluate the quantized model on the training set\n",
    "    train_loss, train_accuracy = model.evaluate(X_train, y_train)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a785e396-4ebc-4d6e-ad6b-e066db4c0f15",
   "metadata": {},
   "source": [
    "In the following section, the model is trained on a total of 40 epochs. After the model is trained, it is converted into a tflite model and quantised. The quantised model is then saved as emotion_quantized.tflite in the root of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e395a8-3e74-4356-b62e-dbf8b5f3924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "print(\"Memory Usage Before:\", psutil.virtual_memory())\n",
    "\n",
    "# for five emotions {neutral , happy ,angry, surprise, sad}\n",
    "\n",
    "dataset = np.array(train_dataset)\n",
    "labels = np.array(train_labels)\n",
    "\n",
    "simple_model = train_vgg(dataset, labels, learning_rate=0.0001, batch_size=128, test_size=0.2, epochs=40, patience=7)\n",
    "# Convert the Keras model to TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(simple_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Enable optimization\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]  # Target INT8 for better performance\n",
    "converter.allow_flexible_interpreter = True  # Allow flexible interpreter for dynamic range support\n",
    "\n",
    "\n",
    "def representative_dataset():\n",
    "    for _ in range(100): \n",
    "        yield [np.random.random_sample((1, 48, 48, 1)).astype(np.float32)]\n",
    "\n",
    "converter.representative_dataset = representative_dataset\n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "\n",
    "with open(\"emotion_quantized.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_quant_model)\n",
    "\n",
    "\n",
    "model_size_bytes = os.path.getsize(\"emotion_quantized.tflite\")\n",
    "model_size_kb = model_size_bytes / 1024  # Convert to kilobytes\n",
    "model_size_mb = model_size_kb / 1024  # Convert to megabytes\n",
    "print(f\"Size of the quantized model: {model_size_bytes} bytes ({model_size_kb:.2f} KB, {model_size_mb:.2f} MB)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
