{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.initializers import  RandomNormal\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 48, 48\n",
    "batch_size = 32\n",
    "\n",
    "# Define the data directories\n",
    "train_data_dir = 'images/train'\n",
    "validation_data_dir = 'images/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7178 images belonging to 7 classes.\n",
      "Found 3668 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "data_gen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,  # Normalize pixel values to [0, 1] by scaling by 255\n",
    "    rotation_range=20, \n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2, \n",
    "    shear_range=0.2,  \n",
    "    zoom_range=0.2,  \n",
    "    vertical_flip=False,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_gen = data_gen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    ")\n",
    "\n",
    "val_gen = data_gen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing CNN structure\n",
    "model = Sequential()\n",
    "\n",
    "# 1st convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding = 'same', input_shape=(img_width, img_height, 3), bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding = 'same', input_shape=(img_width, img_height, 3), bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 3rd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "          \n",
    "# 5th convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 7th convolution layer\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "# Fully connected layers\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 64)        1792      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 48, 48, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 23, 23, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 23, 23, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 23, 23, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 23, 23, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 23, 23, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 11, 11, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 11, 11, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 11, 11, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 11, 11, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 11, 11, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 5, 5, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, 5, 128)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 5, 5, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 5, 5, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 5, 5, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 2, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              2099200   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 14343     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,334,855\n",
      "Trainable params: 3,333,831\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "224/224 [==============================] - 41s 164ms/step - loss: 2.7620 - accuracy: 0.1919 - val_loss: 1.8154 - val_accuracy: 0.2593\n",
      "Epoch 2/100\n",
      "224/224 [==============================] - 11s 51ms/step - loss: 1.8594 - accuracy: 0.2112 - val_loss: 1.9707 - val_accuracy: 0.2612\n",
      "Epoch 3/100\n",
      "224/224 [==============================] - 12s 52ms/step - loss: 1.8381 - accuracy: 0.2267 - val_loss: 1.9679 - val_accuracy: 0.2664\n",
      "Epoch 4/100\n",
      "224/224 [==============================] - 12s 51ms/step - loss: 1.8361 - accuracy: 0.2291 - val_loss: 1.9646 - val_accuracy: 0.2522\n",
      "Epoch 5/100\n",
      "224/224 [==============================] - 12s 51ms/step - loss: 1.8256 - accuracy: 0.2393 - val_loss: 1.9623 - val_accuracy: 0.2596\n",
      "Epoch 6/100\n",
      "224/224 [==============================] - 11s 51ms/step - loss: 1.8248 - accuracy: 0.2319 - val_loss: 1.9667 - val_accuracy: 0.2527\n",
      "Epoch 7/100\n",
      "224/224 [==============================] - 11s 51ms/step - loss: 1.8238 - accuracy: 0.2372 - val_loss: 2.1228 - val_accuracy: 0.2643\n",
      "Epoch 8/100\n",
      "224/224 [==============================] - 11s 51ms/step - loss: 1.8182 - accuracy: 0.2442 - val_loss: 2.2228 - val_accuracy: 0.2623\n",
      "Epoch 9/100\n",
      "224/224 [==============================] - 11s 51ms/step - loss: 1.8167 - accuracy: 0.2473 - val_loss: 2.5336 - val_accuracy: 0.2621\n",
      "Epoch 10/100\n",
      "224/224 [==============================] - 12s 52ms/step - loss: 1.8209 - accuracy: 0.2408 - val_loss: 2.3624 - val_accuracy: 0.2407\n",
      "Epoch 11/100\n",
      "224/224 [==============================] - 11s 50ms/step - loss: 1.8088 - accuracy: 0.2428 - val_loss: 2.3629 - val_accuracy: 0.2270\n",
      "Epoch 12/100\n",
      "224/224 [==============================] - 11s 51ms/step - loss: 1.8118 - accuracy: 0.2464 - val_loss: 2.6603 - val_accuracy: 0.2505\n",
      "Epoch 13/100\n",
      "224/224 [==============================] - 11s 51ms/step - loss: 1.8092 - accuracy: 0.2394 - val_loss: 1.9891 - val_accuracy: 0.2673\n",
      "Epoch 14/100\n",
      "224/224 [==============================] - 11s 51ms/step - loss: 1.8068 - accuracy: 0.2415 - val_loss: 2.5597 - val_accuracy: 0.2404\n",
      "Epoch 15/100\n",
      "224/224 [==============================] - 12s 52ms/step - loss: 1.8027 - accuracy: 0.2520 - val_loss: 2.4137 - val_accuracy: 0.2571\n",
      "Epoch 16/100\n",
      "224/224 [==============================] - 12s 52ms/step - loss: 1.8010 - accuracy: 0.2498 - val_loss: 2.0892 - val_accuracy: 0.2574\n",
      "Epoch 17/100\n",
      "224/224 [==============================] - 12s 51ms/step - loss: 1.8042 - accuracy: 0.2522 - val_loss: 2.4665 - val_accuracy: 0.2407\n",
      "Epoch 18/100\n",
      "224/224 [==============================] - 12s 52ms/step - loss: 1.7946 - accuracy: 0.2566 - val_loss: 2.2104 - val_accuracy: 0.2489\n",
      "Epoch 19/100\n",
      "224/224 [==============================] - 12s 52ms/step - loss: 1.7936 - accuracy: 0.2599 - val_loss: 2.6890 - val_accuracy: 0.2407\n",
      "Epoch 20/100\n",
      "224/224 [==============================] - 12s 53ms/step - loss: 1.7927 - accuracy: 0.2587 - val_loss: 2.0322 - val_accuracy: 0.2695\n",
      "Epoch 21/100\n",
      "224/224 [==============================] - 14s 61ms/step - loss: 1.7899 - accuracy: 0.2565 - val_loss: 1.7930 - val_accuracy: 0.2887\n",
      "Epoch 22/100\n",
      "224/224 [==============================] - 13s 57ms/step - loss: 1.7826 - accuracy: 0.2582 - val_loss: 2.3420 - val_accuracy: 0.2651\n",
      "Epoch 23/100\n",
      "224/224 [==============================] - 13s 56ms/step - loss: 1.7818 - accuracy: 0.2585 - val_loss: 2.1888 - val_accuracy: 0.2700\n",
      "Epoch 24/100\n",
      "224/224 [==============================] - 12s 55ms/step - loss: 1.7712 - accuracy: 0.2614 - val_loss: 2.4069 - val_accuracy: 0.2588\n",
      "Epoch 25/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.7735 - accuracy: 0.2663 - val_loss: 1.8094 - val_accuracy: 0.2717\n",
      "Epoch 26/100\n",
      "224/224 [==============================] - 12s 55ms/step - loss: 1.7682 - accuracy: 0.2629 - val_loss: 2.0858 - val_accuracy: 0.2818\n",
      "Epoch 27/100\n",
      "224/224 [==============================] - 12s 55ms/step - loss: 1.7643 - accuracy: 0.2704 - val_loss: 2.2582 - val_accuracy: 0.2486\n",
      "Epoch 28/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.7653 - accuracy: 0.2678 - val_loss: 2.0693 - val_accuracy: 0.3067\n",
      "Epoch 29/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.7586 - accuracy: 0.2709 - val_loss: 2.0454 - val_accuracy: 0.3015\n",
      "Epoch 30/100\n",
      "224/224 [==============================] - 12s 55ms/step - loss: 1.7586 - accuracy: 0.2673 - val_loss: 2.8943 - val_accuracy: 0.2785\n",
      "Epoch 31/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.7501 - accuracy: 0.2757 - val_loss: 2.1618 - val_accuracy: 0.2777\n",
      "Epoch 32/100\n",
      "224/224 [==============================] - 13s 56ms/step - loss: 1.7432 - accuracy: 0.2830 - val_loss: 1.7757 - val_accuracy: 0.3152\n",
      "Epoch 33/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.7509 - accuracy: 0.2807 - val_loss: 2.6545 - val_accuracy: 0.2873\n",
      "Epoch 34/100\n",
      "224/224 [==============================] - 12s 55ms/step - loss: 1.7423 - accuracy: 0.2813 - val_loss: 2.0416 - val_accuracy: 0.3163\n",
      "Epoch 35/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.7447 - accuracy: 0.2793 - val_loss: 1.8738 - val_accuracy: 0.3166\n",
      "Epoch 36/100\n",
      "224/224 [==============================] - 12s 55ms/step - loss: 1.7353 - accuracy: 0.2802 - val_loss: 1.8782 - val_accuracy: 0.3207\n",
      "Epoch 37/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.7418 - accuracy: 0.2817 - val_loss: 2.0726 - val_accuracy: 0.3100\n",
      "Epoch 38/100\n",
      "224/224 [==============================] - 12s 55ms/step - loss: 1.7433 - accuracy: 0.2845 - val_loss: 1.8875 - val_accuracy: 0.3265\n",
      "Epoch 39/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.7245 - accuracy: 0.2869 - val_loss: 2.1752 - val_accuracy: 0.3166\n",
      "Epoch 40/100\n",
      "224/224 [==============================] - 12s 55ms/step - loss: 1.7243 - accuracy: 0.2874 - val_loss: 2.0050 - val_accuracy: 0.2950\n",
      "Epoch 41/100\n",
      "224/224 [==============================] - 12s 55ms/step - loss: 1.7228 - accuracy: 0.2915 - val_loss: 1.7682 - val_accuracy: 0.3309\n",
      "Epoch 42/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.7149 - accuracy: 0.2964 - val_loss: 2.3325 - val_accuracy: 0.2944\n",
      "Epoch 43/100\n",
      "224/224 [==============================] - 13s 56ms/step - loss: 1.7137 - accuracy: 0.2951 - val_loss: 2.0370 - val_accuracy: 0.2346\n",
      "Epoch 44/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.7198 - accuracy: 0.2891 - val_loss: 2.1537 - val_accuracy: 0.3251\n",
      "Epoch 45/100\n",
      "224/224 [==============================] - 12s 53ms/step - loss: 1.7108 - accuracy: 0.2978 - val_loss: 2.0362 - val_accuracy: 0.3229\n",
      "Epoch 46/100\n",
      "224/224 [==============================] - 12s 53ms/step - loss: 1.7112 - accuracy: 0.2921 - val_loss: 1.7233 - val_accuracy: 0.3300\n",
      "Epoch 47/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.6945 - accuracy: 0.2943 - val_loss: 1.6787 - val_accuracy: 0.3342\n",
      "Epoch 48/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.7037 - accuracy: 0.2918 - val_loss: 2.0482 - val_accuracy: 0.3207\n",
      "Epoch 49/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.7037 - accuracy: 0.2997 - val_loss: 2.0372 - val_accuracy: 0.3128\n",
      "Epoch 50/100\n",
      "224/224 [==============================] - 12s 53ms/step - loss: 1.6873 - accuracy: 0.3045 - val_loss: 1.7681 - val_accuracy: 0.3374\n",
      "Epoch 51/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.6962 - accuracy: 0.3027 - val_loss: 2.3695 - val_accuracy: 0.3136\n",
      "Epoch 52/100\n",
      "224/224 [==============================] - 12s 53ms/step - loss: 1.6795 - accuracy: 0.3016 - val_loss: 1.8403 - val_accuracy: 0.3331\n",
      "Epoch 53/100\n",
      "224/224 [==============================] - 13s 56ms/step - loss: 1.6979 - accuracy: 0.3035 - val_loss: 1.9909 - val_accuracy: 0.3385\n",
      "Epoch 54/100\n",
      "224/224 [==============================] - 12s 55ms/step - loss: 1.6830 - accuracy: 0.3126 - val_loss: 1.8664 - val_accuracy: 0.3522\n",
      "Epoch 55/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.6736 - accuracy: 0.3144 - val_loss: 1.7799 - val_accuracy: 0.3643\n",
      "Epoch 56/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.6712 - accuracy: 0.3193 - val_loss: 1.6807 - val_accuracy: 0.3544\n",
      "Epoch 57/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.6608 - accuracy: 0.3284 - val_loss: 2.0218 - val_accuracy: 0.3624\n",
      "Epoch 58/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.6456 - accuracy: 0.3361 - val_loss: 1.6542 - val_accuracy: 0.3684\n",
      "Epoch 59/100\n",
      "224/224 [==============================] - 12s 55ms/step - loss: 1.6526 - accuracy: 0.3417 - val_loss: 1.8824 - val_accuracy: 0.3536\n",
      "Epoch 60/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.6496 - accuracy: 0.3346 - val_loss: 1.9397 - val_accuracy: 0.3679\n",
      "Epoch 61/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.6415 - accuracy: 0.3356 - val_loss: 1.7873 - val_accuracy: 0.3731\n",
      "Epoch 62/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.6353 - accuracy: 0.3452 - val_loss: 1.6715 - val_accuracy: 0.3917\n",
      "Epoch 63/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.6369 - accuracy: 0.3484 - val_loss: 1.9562 - val_accuracy: 0.3668\n",
      "Epoch 64/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.6344 - accuracy: 0.3469 - val_loss: 1.7062 - val_accuracy: 0.4038\n",
      "Epoch 65/100\n",
      "224/224 [==============================] - 12s 55ms/step - loss: 1.6211 - accuracy: 0.3503 - val_loss: 1.8709 - val_accuracy: 0.3802\n",
      "Epoch 66/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.6167 - accuracy: 0.3547 - val_loss: 1.7288 - val_accuracy: 0.3884\n",
      "Epoch 67/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.6172 - accuracy: 0.3587 - val_loss: 1.5225 - val_accuracy: 0.4158\n",
      "Epoch 68/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.6040 - accuracy: 0.3567 - val_loss: 2.1955 - val_accuracy: 0.3805\n",
      "Epoch 69/100\n",
      "224/224 [==============================] - 12s 55ms/step - loss: 1.6126 - accuracy: 0.3624 - val_loss: 1.9707 - val_accuracy: 0.4208\n",
      "Epoch 70/100\n",
      "224/224 [==============================] - 12s 55ms/step - loss: 1.5887 - accuracy: 0.3678 - val_loss: 1.7683 - val_accuracy: 0.4191\n",
      "Epoch 71/100\n",
      "224/224 [==============================] - 12s 55ms/step - loss: 1.5915 - accuracy: 0.3641 - val_loss: 1.8595 - val_accuracy: 0.4049\n",
      "Epoch 72/100\n",
      "224/224 [==============================] - 12s 55ms/step - loss: 1.5953 - accuracy: 0.3683 - val_loss: 2.2726 - val_accuracy: 0.4134\n",
      "Epoch 73/100\n",
      "224/224 [==============================] - 14s 64ms/step - loss: 1.5906 - accuracy: 0.3673 - val_loss: 1.5561 - val_accuracy: 0.4411\n",
      "Epoch 74/100\n",
      "224/224 [==============================] - 14s 63ms/step - loss: 1.5749 - accuracy: 0.3799 - val_loss: 1.7653 - val_accuracy: 0.4285\n",
      "Epoch 75/100\n",
      "224/224 [==============================] - 15s 66ms/step - loss: 1.5665 - accuracy: 0.3792 - val_loss: 1.6685 - val_accuracy: 0.4290\n",
      "Epoch 76/100\n",
      "224/224 [==============================] - 14s 64ms/step - loss: 1.5615 - accuracy: 0.3894 - val_loss: 1.9753 - val_accuracy: 0.4339\n",
      "Epoch 77/100\n",
      "224/224 [==============================] - 20s 87ms/step - loss: 1.5550 - accuracy: 0.3910 - val_loss: 1.6546 - val_accuracy: 0.4424\n",
      "Epoch 78/100\n",
      "224/224 [==============================] - 16s 72ms/step - loss: 1.5604 - accuracy: 0.3847 - val_loss: 1.8696 - val_accuracy: 0.4361\n",
      "Epoch 79/100\n",
      "224/224 [==============================] - 17s 75ms/step - loss: 1.5509 - accuracy: 0.3953 - val_loss: 5.4721 - val_accuracy: 0.3882\n",
      "Epoch 80/100\n",
      "224/224 [==============================] - 16s 72ms/step - loss: 1.5385 - accuracy: 0.3901 - val_loss: 1.5185 - val_accuracy: 0.4641\n",
      "Epoch 81/100\n",
      "224/224 [==============================] - 13s 60ms/step - loss: 1.5364 - accuracy: 0.3932 - val_loss: 1.8004 - val_accuracy: 0.4383\n",
      "Epoch 82/100\n",
      "224/224 [==============================] - 14s 62ms/step - loss: 1.5426 - accuracy: 0.3978 - val_loss: 2.1889 - val_accuracy: 0.4556\n",
      "Epoch 83/100\n",
      "224/224 [==============================] - 14s 62ms/step - loss: 1.5337 - accuracy: 0.3941 - val_loss: 1.5741 - val_accuracy: 0.4359\n",
      "Epoch 84/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.5233 - accuracy: 0.4071 - val_loss: 3.2009 - val_accuracy: 0.4010\n",
      "Epoch 85/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.5345 - accuracy: 0.3955 - val_loss: 1.4831 - val_accuracy: 0.4718\n",
      "Epoch 86/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.5216 - accuracy: 0.4061 - val_loss: 2.5293 - val_accuracy: 0.4438\n",
      "Epoch 87/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.5290 - accuracy: 0.4046 - val_loss: 1.6855 - val_accuracy: 0.4285\n",
      "Epoch 88/100\n",
      "224/224 [==============================] - 12s 54ms/step - loss: 1.5048 - accuracy: 0.4085 - val_loss: 1.5214 - val_accuracy: 0.4501\n",
      "Epoch 89/100\n",
      "224/224 [==============================] - 13s 56ms/step - loss: 1.5151 - accuracy: 0.4120 - val_loss: 1.8382 - val_accuracy: 0.4616\n",
      "Epoch 90/100\n",
      "224/224 [==============================] - 13s 57ms/step - loss: 1.5066 - accuracy: 0.4121 - val_loss: 1.4686 - val_accuracy: 0.4427\n",
      "Epoch 91/100\n",
      "224/224 [==============================] - 13s 60ms/step - loss: 1.5032 - accuracy: 0.4156 - val_loss: 1.4975 - val_accuracy: 0.4627\n",
      "Epoch 92/100\n",
      "224/224 [==============================] - 15s 68ms/step - loss: 1.4953 - accuracy: 0.4134 - val_loss: 1.6177 - val_accuracy: 0.4646\n",
      "Epoch 93/100\n",
      "224/224 [==============================] - 13s 58ms/step - loss: 1.4835 - accuracy: 0.4239 - val_loss: 1.7202 - val_accuracy: 0.4668\n",
      "Epoch 94/100\n",
      "224/224 [==============================] - 13s 57ms/step - loss: 1.4867 - accuracy: 0.4209 - val_loss: 1.5594 - val_accuracy: 0.4770\n",
      "Epoch 95/100\n",
      "224/224 [==============================] - 13s 59ms/step - loss: 1.4837 - accuracy: 0.4180 - val_loss: 1.4603 - val_accuracy: 0.4737\n",
      "Epoch 96/100\n",
      "224/224 [==============================] - 13s 57ms/step - loss: 1.4784 - accuracy: 0.4263 - val_loss: 2.2993 - val_accuracy: 0.4583\n",
      "Epoch 97/100\n",
      "224/224 [==============================] - 13s 57ms/step - loss: 1.4775 - accuracy: 0.4200 - val_loss: 1.4642 - val_accuracy: 0.4860\n",
      "Epoch 98/100\n",
      "224/224 [==============================] - 13s 57ms/step - loss: 1.4549 - accuracy: 0.4362 - val_loss: 1.3782 - val_accuracy: 0.4846\n",
      "Epoch 99/100\n",
      "224/224 [==============================] - 13s 57ms/step - loss: 1.4740 - accuracy: 0.4221 - val_loss: 1.4448 - val_accuracy: 0.4893\n",
      "Epoch 100/100\n",
      "224/224 [==============================] - 13s 57ms/step - loss: 1.4584 - accuracy: 0.4334 - val_loss: 1.6798 - val_accuracy: 0.4852\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 100\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=train_gen.samples // batch_size,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_gen.samples // batch_size,\n",
    "    epochs=epochs)\n",
    "\n",
    "model.save(\"cnnModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model('cnnModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 9s 37ms/step - loss: 1.6961 - accuracy: 0.4638\n",
      "Loss: 1.6960623264312744\n",
      "Accuracy: 0.46377819776535034\n"
     ]
    }
   ],
   "source": [
    "scores = model2.evaluate(train_gen, batch_size=1024)\n",
    "print(\"Loss: \" + str(scores[0]))\n",
    "print(\"Accuracy: \" + str(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 4s 35ms/step\n",
      "Confusion Matrix\n",
      "[[  3   0  11  97  80 124  68]\n",
      " [  0   0   0  15   5  18   8]\n",
      " [  6   0  17 109 114 154  69]\n",
      " [ 14   0  24 234 246 317 144]\n",
      " [  7   0  24 175 148 236 103]\n",
      " [ 10   0  24 159 168 214  97]\n",
      " [  7   0  18 110 102 133  56]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.06      0.01      0.01       383\n",
      "     Disgust       0.00      0.00      0.00        46\n",
      "        Fear       0.14      0.04      0.06       469\n",
      "       Happy       0.26      0.24      0.25       979\n",
      "         Sad       0.17      0.21      0.19       693\n",
      "    Surprise       0.18      0.32      0.23       672\n",
      "     Neutral       0.10      0.13      0.12       426\n",
      "\n",
      "    accuracy                           0.18      3668\n",
      "   macro avg       0.13      0.14      0.12      3668\n",
      "weighted avg       0.17      0.18      0.17      3668\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\techn\\anaconda3\\envs\\gpu_fix\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\techn\\anaconda3\\envs\\gpu_fix\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\techn\\anaconda3\\envs\\gpu_fix\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(val_gen)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(val_gen.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "print(classification_report(val_gen.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_fix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
